---
title: "BCB420 Assignment 1 (Kevin Lu)"
output:
  html_document:
    df_print: paged
---

I'll be using a dataset studying the effect of SARS-CoV-2 spike proteins on
human lung cells ([GSE185657](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE185657)).
COVID-19 continues to be the topic on everybody's minds after two years, so I
thought I would analyze a dataset related to the virus causing it.

## 1. Download from GEO.

```{r}
library(GEOmetadb)
library(GEOquery)
```
Download the metadata GEO series, or load from disk if already downloaded.

```{r}
if (!file.exists("GSE185657.rds")) {
  gse <- getGEO("GSE185657")
  saveRDS("GSE185657.rds")
} else {
  gse <- readRDS("GSE185657.rds") 
}
```

There are 24 samples in this series.
```{r}
length(GSMList(gse))
```

The supplementary tarball for this dataset contains the raw counts, distributed
across one file for each sample. We can construct the counts matrix since all
files have the same length and the same Ensembl gene IDs in the same order.

```{r}
if (!file.exists("GSE185657_RAW.tar")) {
  files <- getGEOSuppFiles("GSE185657", makeDirectory=FALSE)
  target <- rownames(files[1])
} else{
  target <- "./GSE185657_RAW.tar"
}
contents <- untar(target, list=TRUE)
contents
```

For some reason, instead of a compressed tarball, the authors compressed each
_individual_ file and then combined them into one archive. Extract each sample.
```{r, results='hide'}
# Remove all extracted files to reperform the extraction and decompression
if (!file.exists("GSM5621226_A_C1.txt")) {
  untar(target)
  lapply(contents, gunzip)
}
```

Finally, construct the counts matrix.
```{r}
targets <- gsub(".gz$", "", contents)
raw_list <- lapply(targets, read.delim)
genes <- raw_list[[1]]$Ensembl_gene_ID
samples <- sapply(raw_list, function (sample) colnames(sample)[2])
counts <- sapply(raw_list, function(sample) sample[[2]])
rownames(counts) <- genes
colnames(counts) <- samples
```

## 2. Assess

Here are some details regarding the conditions of the experiment and overview
statistics on the data.

```{r}
Meta(gse)$title
```

```{r}
Meta(gse)$overall_design
```

```{r}
Meta(gse)$last_update_date
```

```{r}
Meta(gse)$summary
```

Confirm the prior assertions regarding the structure of the raw files.
```{r}
all(sapply(raw_list, function(sample) all.equal(genes, sample$Ensembl_gene_ID)))
```

```{r}
length(unique(genes)) == length(genes)
```

45368 genes were measured across 24 samples. According to the authors, this is
an RNA-Seq dataset sequenced with Illumina NextSeq 500. The recorded values are
CPM values, mapped to the GRCh38 genome assembly.

```{r}
dim(counts)
```

```{r}
knitr::kable(head(counts), format="html")
```

## 3. Map to HUGO gene symbols

Conveniently, we already have a unique list of GRCh38 Ensembl gene IDs for this
dataset. We can get the gene symbols with `biomaRt`, which might be more helpful
for human interpretation.

```{r}
GRCh38 <- biomaRt::useEnsembl("genes", "hsapiens_gene_ensembl")
ensg2hgnc <- biomaRt::getBM(c("ensembl_gene_id", "hgnc_symbol"), mart=GRCh38)
```

There isn't necessarily a gene symbol for a particular Ensembl ID.
```{r}
gene_symbols <- ensg2hgnc$hgnc_symbol[match(genes, ensg2hgnc$ensembl_gene_id)]
any(gene_symbols == "")
any(is.na(gene_symbols))
```

## 4. Clean as necessary

From lecture 4, according to the `edgeR` protocol, it is recommended to remove
features with insufficient reads. In this experiment, there are six replicates
per group (alveolar and bronchial cells with and without spike protein).

How many genes would be kept if the ones without at least one read per million
in six samples were removed?
```{r}
sum(rowSums(counts > 1) >= 6)
```

About two-thirds of genes are dropped. However, some Ensembl IDs still do not
have corresponding symbols.

```{r}
filtered_counts <- counts[rowSums(counts > 1) >= 6, ]
filtered_symbols <- ensg2hgnc$hgnc_symbol[match(rownames(filtered_counts), ensg2hgnc$ensembl_gene_id)]
any(filtered_symbols == "")
any(is.na(filtered_symbols))
```

## 5. Apply normalization

Per lecture 4, let's get box plots of these CPMs pre-normalization.

```{r}
data2plot <- log2(filtered_counts)
boxplot(data2plot, xlab = "Samples", ylab = "log2 CPM", 
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "GSE185657 samples pre-normalization")
#draw the median on each box plot
abline(h = median(apply(data2plot, 2, median)), col = "green", lwd = 0.6, lty = "dashed")
```
Even after cleaning, some samples still have 0 CPM for a feature, which results
in -Inf logarithms for the plot.

As for density, again following the lecture slides:

```{r}
counts_density <- apply(log2(filtered_counts), 2, density)
#calculate the limits across all the samples
xlim <- 0; ylim <- 0
for (i in 1:length(counts_density)) {
  xlim <- range(c(xlim, counts_density[[i]]$x)); 
  ylim <- range(c(ylim, counts_density[[i]]$y))
}
cols <- rainbow(length(counts_density))
ltys <- rep(1, length(counts_density))
#plot the first density plot to initialize the plot
plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
     ylab="Smoothing density of log2-CPM", 
     main="GSE185657 samples pre-normalization", cex.lab = 0.85)
#plot each line
for (i in 1:length(counts_density)) 
  lines(counts_density[[i]], col=cols[i], lty=ltys[i])
#create legend
legend("topright", colnames(data2plot),  
       col=cols, lty=ltys, cex=0.75, 
       border ="blue",  text.col = "green4", 
       merge = TRUE, bg = "gray90")
```
This looks kind of funny.

Since we are already using `edgeR` for this RNA-Seq dataset, let's apply TMM
normalization to the filtered CPMs.

```{r}
groups <- gsub("\\d", "", colnames(filtered_counts))
d <- edgeR::DGEList(filtered_counts, group = groups)
d <- edgeR::calcNormFactors(d)
normalized_counts <- edgeR::cpm(d)
```

```{r}
data2plot <- log2(normalized_counts)
boxplot(data2plot, xlab = "Samples", ylab = "log2 CPM", 
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "GSE185657 samples post-normalization")
#draw the median on each box plot
abline(h = median(apply(data2plot, 2, median)), col = "green", lwd = 0.6, lty = "dashed")
```

```{r}
counts_density <- apply(log2(normalized_counts), 2, density)
#calculate the limits across all the samples
xlim <- 0; ylim <- 0
for (i in 1:length(counts_density)) {
  xlim <- range(c(xlim, counts_density[[i]]$x)); 
  ylim <- range(c(ylim, counts_density[[i]]$y))
}
cols <- rainbow(length(counts_density))
ltys <- rep(1, length(counts_density))
#plot the first density plot to initialize the plot
plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
     ylab="Smoothing density of log2-CPM", 
     main="GSE185657 samples post-normalization", cex.lab = 0.85)
#plot each line
for (i in 1:length(counts_density)) 
  lines(counts_density[[i]], col=cols[i], lty=ltys[i])
#create legend
legend("topright", colnames(data2plot),  
       col=cols, lty=ltys, cex=0.75, 
       border ="blue",  text.col = "green4", 
       merge = TRUE, bg = "gray90")
```

## 6. Interpretation

Most of these were implicitly addressed above.

**What are the control and test conditions of the dataset?**
**Why is the dataset of interest to you?**
**Were there expression values that were not unique for specific genes? How did you handle these?**
**Were there expression values that could not be mapped to current HUGO symbols?**
**How many outliers were removed?**
**How did you handle replicates?**
**What is the final coverage of your dataset?**

## 7. Citations

Rahman M, Irmler M, Keshavan S, Introna M et al. Differential Effect of SARS-CoV-2 Spike Glycoprotein 1 on Human Bronchial and Alveolar Lung Mucosa Models: Implications for Pathogenicity. Viruses 2021 Dec 17;13(12). PMID: [34960806](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8708014/)

```{r}
citation("GEOmetadb")
citation("GEOquery")
citation("biomaRt")
citation("edgeR")
```
